---
title: 电商广告点击分析系统
tags: Flume,Kafka,SparkStreaming
grammar_cjkRuby: true
grammar_mindmap: true
renderNumberedHeading: true
---

# 核心需求

1、在线黑名单过滤
2、计算每个BatchDuration中每个User的广告点击量
3、判断用户点击是否属于黑名单点击
4、广告点击累计动态更新
5、对广告点击进行TopN
6、计算过去半个小时广告的点击趋势

# 技术选型
 假设我们的应用系统对应的用户的日活量在百万的基础上来实现此架构。


## Flume的简介
apache Flume 是一个从可以收集例如日志，事件等数据资源，并将这些数量庞大的数据从各项数据资源中集中起来存储的工具/服务，或者数集中机制。flume具有高可用，分布式，配置工具，其设计的原理也是基于将数据流，如日志数据从各种网站服务器上汇集起来存储到HDFS，HBase等集中存储器中。

![2.1 Flume复杂流结构模型](https://www.github.com/Tu-maimes/document/raw/master/小书匠/多路复杂.jpg)



### Flume的优势


1、Flume可以将应用产生的数据存储到任何集中存储器中，例如HDFS、HBase、Kafka等。
2、当收集数据的速度超过将写入数据的时候，也就是当收集信息遇到峰值时，这时候收集的信息非常大，甚至超过了系统的写入数据的能力，Flume会在数据生产者和数据收容器间做出调整，保证其能够在两者之间提供平稳的数据。
3、Flume的管道是基于事务，保证了数据在传送和接收时的一致性。
4、Flume是可靠的，容错性高，可升级，易管理，并且可定制。
5、支持各种接入资源数据的类型以及输出数据的类型。
6、支持多路径流量，多管道接入流量，多管道输出流量，上下文路由等。
7、可以被水平扩展。


### Flume性能测试

#### 测试环境

##### 硬件

- CPU：Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz（8核）
- 内存：16G

##### 软件

- Flume：1.6.0
- Hadoop：2.6.0-cdh5.5.0
- Kfaka：2.11-0.9.0.1
- JDK：1.8.0_91-b14 64位

##### 测试文件

- 文件大小：107M ，共490010条记录

##### Flume配置

1、Source配置:
> agent.sources.source1.type = spooldir
> agent.sources.source1.spoolDir=/data/flume/dir

2、MemoryChannel配置
>agent.channels.memoryChannel.capacity = 1000000
agent.channels.memoryChannel.transactionCapacity = 1000000
agent.channels.memoryChannel.type=memory

3、FileChannel配置

> agent.channels.fileChannel.type = file
agent.channels.fileChannel.checkpointDir = /data/flume/checkpoint
agent.channels.fileChannel.dataDirs = /data/flume/data

4、JVM配置

>JAVA_OPTS="-Xms256m -Xmx256m -Xss256k -Xmn128m -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:-UseGCOverheadLimit"


#### 写入文件性能

|  FlumeConfig   |Time(s)     |  Throughput（events/s）   |
| --- | --- | --- |
|MemoryChannel+FileSink	|51|	9608|
|FileChannel+FileSink|	250	|1960|

#### 写入Kafka性能

|  FlumeConfig   |Time(s)     |  Throughput（events/s）   |
| --- | --- | --- |
|KafkaSink+MemoryChannel|	57	|8597|
|KafkaChannel	|50|	9800|
|KafkaSink+FileChannel|	830|	590|

#### 写入HDFS性能

|  FlumeConfig   |Time(s)     |  Throughput（events/s）   |
| --- | --- | --- |
|FileChannel+HdfsSink	|148|	3311|



## Logstash简介










## Kafka简介

Kafka 是一款开源的、轻量级的 、分布式、可分区和具有复制备份的 (Replicated)、基于ZooKeeper 协调管理的分布式流平台的功能强大的消息系统 。 
Kafka 定位就是一个分布式流处理平台。作为一个流式处理平台，必须满足以下三个关键特性：
- 能够允许发布和订阅流数据。
- 存储流数据时提供相应的容错机制。
- 当流数据到达时能被及时处理。

![Kafka消息系统最基本的体系架构](https://www.github.com/Tu-maimes/document/raw/master/小书匠/kafka.jpg)

- 消息生产者(Producer):将消息写入kafka集群。
- 消息消费者(Consumer):从kafka集群中拉取消息。

### Kafka的优势

 消息系统的特点：生存者消费者模型，先入先出（FIFO）

• 高性能：单节点支持上千个客户端，高吞吐量

1.     零拷贝技术

2.     分布式存储

3.     顺序读顺序写

4.     批量读批量写

• 持久性：消息直接持久化在普通磁盘上，且性能好

• 分布式：数据副本冗余、流量负载均衡、可扩展

• 很灵活：消息长时间持久化+Client维护消费状态

注意：消息系统基本的特点是保证了，有基本的生产者消费者模型，partition内部是FIFO 的，partition之间不是FIFO，当然我们可以把topic设为一个partition，这样就严格的FIFO

### Kafka性能测试

[参考文档](https://www.cnblogs.com/smartloli/p/10093838.html)

#### 测试环境

本次测试的环境信息由三台物理机组成，具体信息：

|主机名|Kafka版本|CPU|内存|磁盘|网卡|
| --- | --- | --- | --- | --- | --- |
|dn1|0.10.2.0|32核|64GB|12x4T|千兆|
|dn2|0.10.2.0|32核|64GB|12x4T|千兆|
|dn3|0.10.2.0|32核|64GB|12x4T|千兆|

#### 生产者测试

生产者测试，分别从线程数、分区数、副本数、Broker数、同步与异步模式、批处理大小、消息长度大小、数据压缩等。

##### 线程数
![](https://www.github.com/Tu-maimes/document/raw/master/小书匠/1561030637347.png)

结论：向一个拥有6个分区、1个副本的Topic中，发送500万条消息记录时，随着线程数的增加，每秒发送的消息记录会逐渐增加。在线程数为25时，每秒发送的消息记录达到最佳值，随后再增加线程数，每秒发送的消息记录数反而会减少。

##### 分区数

![](https://www.github.com/Tu-maimes/document/raw/master/小书匠/1561031339014.png)

总结：从测试结果来看，分区数越多，单线程生产者的吞吐量越小。

##### 副本数

![](https://www.github.com/Tu-maimes/document/raw/master/小书匠/1561079067158.png)

总结：从测试结果来看，副本数越多，吞吐量越小。

##### Broker数量

![](https://www.github.com/Tu-maimes/document/raw/master/小书匠/1561079171982.png)

总结：从测试结果来看，增加Kafka Broker数量，吞吐量会增加。

##### 同步与异步模式

![](https://www.github.com/Tu-maimes/document/raw/master/小书匠/1561079326258.png)

总结：从测试结果来看，使用异步模式发送消息数据，比使用同步模式发送消息数据，吞吐量是同步模式的3倍左右。

##### 批处理大小

![](https://www.github.com/Tu-maimes/document/raw/master/小书匠/1561079604995.png)

总结：从测试的结果来看，发送的消息随着批处理大小增加而增加。当批处理大小增加到3000~5000时，吞吐量达到最佳状态，而后在增加批处理大小，吞吐量的性能会下降。

##### 消息长度的大小

![](https://www.github.com/Tu-maimes/document/raw/master/小书匠/1561080132100.png)

总结：从测试结果来看，随着消息长度的增加，每秒所能发送的消息逐渐减少（nMsg/sec）。但是，每秒发送的消息的总大小（MB/sec),会随着消息长度的增加而增加。

#### Kafka消费者测试

消费者测试，可以从线程数、分区数、副本数等维度来进行测试。

##### 线程数

![](https://www.github.com/Tu-maimes/document/raw/master/小书匠/1561080799340.png)

总结：随着线程数的增加，每秒读取的消息记录会逐渐增加。在线程数与消费主题的分区相等时，吞吐量达到最佳值。随后，再增加线程数，新增的线程数将会处于空闲状态，对提升消费者程序的吞吐量没有帮助。

##### 分区数

![](https://www.github.com/Tu-maimes/document/raw/master/小书匠/1561081154469.png)

总结：当分区数增加时，如果线程数保持不变，则消费者程序的吞吐量性能会下降。

##### 副本数

![](https://www.github.com/Tu-maimes/document/raw/master/小书匠/1561081268274.png)

总结：副本数对消费者程序的吞吐量影响较小，消费者程序是从Topic的每个分区的Leader上读取数据的，而与副本数无关。 

## SparkStreaming简介

Spark Streaming是核心Spark API的扩展，可实现实时数据流的可扩展，高吞吐量，容错流处理。数据可以从许多来源（如Kafka，Flume，Kinesis或TCP套接字）中提取，并且可以使用以高级函数表示的复杂算法进行处理map，例如reduce，join和window。最后，处理后的数据可以推送到文件系统，数据库和实时仪表板。

![SparkStreaming体系架构](https://www.github.com/Tu-maimes/document/raw/master/小书匠/1561083559745.png)

### 检查点

- 元数据检查点 - 将定义流式计算的信息保存到容错存储（如HDFS）。这用于从运行流应用程序的驱动程序的节点的故障中恢复（稍后详细讨论）。元数据包括：
 1、配置 - 用于创建流应用程序的配置。
 2、DStream操作 - 定义流应用程序的DStream操作集。
 3、不完整的批次 - 其工作排队但尚未完成的批次。
- 数据检查点 - 将生成的RDD保存到可靠的存储。在一些跨多个批次组合数据的有状态转换中，这是必需的。在这种转换中，生成的RDD依赖于先前批次的RDD，这导致依赖关系链的长度随时间增加。为了避免恢复时间的这种无限增加（与依赖链成比例），有状态变换的中间RDD周期性地 检查点到可靠存储（例如HDFS）以切断依赖链。
总而言之，元数据检查点主要用于从驱动程序故障中恢复，而如果使用状态转换，即使对于基本功能也需要数据或RDD检查点。

#### 启用检查点

必须为具有以下任何要求的应用程序启用检查点：

- 有状态转换的用法 - 如果在应用程序中使用了（updateStateByKey或reduceByKeyAndWindow使用反函数），则必须提供检查点目录以允许定期RDD检查点。
- 从运行应用程序的驱动程序的故障中恢复 - 元数据检查点用于使用进度信息进行恢复。


请注意，可以在不启用检查点的情况下运行没有上述有状态转换的简单流应用程序。在这种情况下，驱动程序故障的恢复也将是部分的（某些已接收但未处理的数据可能会丢失）。这通常是可以接受的，并且许多以这种方式运行Spark Streaming应用程序。预计对非Hadoop环境的支持将在未来得到改善。

#### 配置检查点

可以通过在容错，可靠的文件系统（例如，HDFS，S3等）中设置目录来启用检查点，检查点信息将保存到该文件系统中。这是通过使用完成的streamingContext.checkpoint(checkpointDirectory)。这将允许您使用上述有状态转换。此外，如果要使应用程序从驱动程序故障中恢复，则应重写流应用程序以使其具有以下行为。

- 当程序第一次启动时，它将创建一个新的StreamingContext，设置所有流然后调用start（）。
- 当程序在失败后重新启动时，它将从检查点目录中的检查点数据重新创建StreamingContext。

### SparkStreaming与Kafka的集成

Kafka 0.10的Spark Streaming集成它提供简单的并行性，Kafka分区和Spark分区之间的1：1对应关系，以及对偏移和元数据的访问。
[Spark官网集成文档](http://spark.apache.org/docs/latest/streaming-kafka-0-10-integration.html)
[两种接受方式比较](https://www.cnblogs.com/liugh/articles/6817553.html)

SparkStreaming使用NoReceivers方式读取Kafka数据	
	SparkStreaming读取Kafka数据支撑有两种方式：Receiver方式和NoReceiver方式
	1、Receiver方式：SparkStreamingKafkaUtil使用createStream方法
	2、NoReceivers方式：SparkStreamingKafkaUtil使用createDirectStream方法
	NOReceivers方式在企业中使用的越来越多，具有更强的自由度控制、语义一致性。NO Receivers
	更符合数据读取和数据操作，是我们操作数据来源的自然方式。
	
采用No Receivers 方式直接抓取Kafka数据带来的好处：
	1、No Receivers方式直接抓取Kafka的数据，没有缓存，不会出现内存溢出的问题。如果使用kafakReceiver方式读取数据，会存在内存的问题。需要设置kafka Receiver读取的频率和block Interval等信息
	2、如果采用Receivers方式，Receivers默认情况需要和Worker的Executor绑定，不方便做分布式。如果采用No Receivers direct方式，默认情况下数据会在多个Worker上的Executor，数据天然就是分布式，默认分布在多个Executor上。而Receivers方式就不方便计算。
	3、数据消费的问题，在实际操作的时候采用Receivers的方式有一个弊端，消费数据来不及处理，如果延迟多次SparkStreaming程序就有可能崩溃。但是是采用No REceivers Direct方式访问Kafka数据，就不会存在此问题。因为NO Receivers direct方式直接读取Kafka数据，如果数据有延迟delay，那就不进行下一个处理，因此，No Receivers direct方式就不会存在来不及消费、程序崩溃的问题。
	4、No Receivers direct方式实现完全的语义一致性，不会重复消费数据，而且保证数据一定被消费。No Receivers direct方式与Kafka进行交互，只有数据真正执行成功后才会记录下来。
	
采用 No Receivers方式
	1、无接收器：createDirectStream方式不使用任何接收器，直接从Kafka进群进行查询(新版本已取消Receiver)
	2、偏移量：createDirectStream方式不使用Zookeeper存储偏移量。消费的偏移量由Stream本身进行跟踪记录。Kafka的监控依赖于Zookeeper，为了监控Stream的消费信息，通过获取偏移量更新Kafka、Zookeeper的偏移量。
	3、容错恢复：如果是SparkDirver容错恢复，可以在StreamingContext中启用检查点。消费的偏移量可以从检查点恢复。
	4、端到端的语义：确保每个记录有效接收和转换一次，但不保证转换以后的数据只输出一次。
	

### Kafka偏移量存储

- 检查点
- Kafka本身
- 自定义存储


# 电商广告点击系统架构

本架构主要是通过分布式Flume采集web系统的数据汇聚到Kafka消息系统，以及对数据实现备份。Kafak消息系统中的数据提供给SparkStreaming进行流式处理，处理的结果存储到数据库中供其他系统使用。
![架构图](https://www.github.com/Tu-maimes/document/raw/master/小书匠/Spark流处理.jpg)