# 指定Agent的组件名称
a1.sources = r1
a1.sinks = k1 k2
a1.channels = c1 c2
 
# 指定Flume source(要监听的路径)
a1.sources.r1.type = com.yss.source.taildir.TaildirSource
a1.sources.r1.positionFile = /data/temp/ws/taildir_position.json
a1.sources.r1.filegroups = f1
a1.sources.r1.filegroups.f1 = /data/gz_interface/(.*\.(DBF|dbf|xml|XML|tsv|TSV|txt|TXT|xls|XLS|xlsx|XLSX)$)
#a1.sources.r1.filegroups.f1 = /data/gz_interface/^((?!\.xls[x|d]$).)*$
a1.sources.r1.filegroups.f1.headerKey1 = value1
a1.sources.r1.recursiveDirectorySearch = true
#指定Xml文件的节点key值,不指定默认Security
a1.sources.r1.xmlNode = exchangerate
#指定csv文件的分隔符,不指定默认逗号分隔
#a1.sources.r1.csvSeparator = ,
#指定是否需要文件的相对路径,默认ture
a1.sources.r1.fileHeader = true
#指定获取文件相对路径的key值,默认值fileName
a1.sources.r1.fileHeaderKey = fileName
#指定当前行的行号的key值,默认值是currentRecord
a1.sources.r1.currentLine = currentRecord
#每个event中所包含多少行的数据
a1.sources.r1.eventLines = 50
#读完文件后是否修改文件的名字,默认为false
#a1.sources.r1.renameFlie = true
#配置DBF文件的前缀匹配,默认值是不以文件的前缀匹配 注意:字符串中间不要有空格
a1.sources.r1.prefixStr = gzlx,zqye,qtsl,zqbd,zqjsxx,hk_jsmx,hk_tzxx,hk_zqbd,hk_zqye,hk_ckhl,abcsj,ywhb,zjhz,wdq,hk_zjbd,hk_zjhz,hk_zjye,jsmxjs,op_bzjzh
#配置是否发送文件的头,默认值是true发送头文件
#a1.sources.r1.headFile = true





# 指定Flume hdfs sink
a1.sinks.k1.type = com.yss.sink.hdfs.HDFSEventSink
a1.sinks.k1.hdfs.path = /yss/guzhi/interface/
a1.sinks.k1.hdfs.filePrefix = %{fileName}
a1.sinks.k1.hdfs.fileSuffix = .csv
a1.sinks.k1.hdfs.rollCount = 0
a1.sinks.k1.hdfs.fileType  = DataStream
a1.sinks.k1.hdfs.writeFormat  = Text
a1.sinks.k1.hdfs.rollSize = 0
#a1.sinks.k1.hdfs.idleTimeout  = 5
a1.sinks.k1.hdfs.round = true
a1.sinks.k1.hdfs.rollInterval = 0
a1.sinks.k1.hdfs.useLocalTimeStamp = true

# 指定Flume kafka sink
a1.sinks.k2.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k2.kafka.topic = flume_kafka
a1.sinks.k2.kafka.bootstrap.servers = bj-rack001-hadoop004:6667,bj-rack001-hadoop002:6667,bj-rack001-hadoop003:6667
a1.sinks.k2.kafka.flumeBatchSize = 20
a1.sinks.k2.useFlumeEventFormat = true


 
# 指定Flume hdfs channel
a1.channels.c1.type = memory
a1.channels.c1.capacity = 10000
a1.channels.c1.transactionCapacity = 10000
#a1.channels.c1.byteCapacityBufferPercentage = 20
#a1.channels.c1.byteCapacity = 80000000


# 指定Flume kafka channel
a1.channels.c2.type = memory
a1.channels.c2.capacity = 10000
a1.channels.c2.transactionCapacity = 10000
#a1.channels.c2.byteCapacityBufferPercentage = 20
#a1.channels.c2.byteCapacity = 80000000


 
# 绑定source和sink到channel上
a1.sources.r1.channels = c1 c2
a1.sinks.k1.channel = c1
a1.sinks.k2.channel = c2

